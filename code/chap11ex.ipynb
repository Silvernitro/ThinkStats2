{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples and Exercises from Think Stats, 2nd Edition\n",
    "\n",
    "http://thinkstats2.com\n",
    "\n",
    "Copyright 2016 Allen B. Downey\n",
    "\n",
    "MIT License: https://opensource.org/licenses/MIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "import thinkstats2\n",
    "import thinkplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple regression\n",
    "\n",
    "Let's load up the NSFG data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import first\n",
    "\n",
    "live, firsts, others = first.MakeFrames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's birth weight as a function of mother's age (which we saw in the previous chapter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>totalwgt_lb</td>   <th>  R-squared:         </th> <td>   0.005</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.005</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   43.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 27 Jun 2018</td> <th>  Prob (F-statistic):</th> <td>5.72e-11</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:06:50</td>     <th>  Log-Likelihood:    </th> <td> -15897.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  9038</td>      <th>  AIC:               </th> <td>3.180e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9036</td>      <th>  BIC:               </th> <td>3.181e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    6.8304</td> <td>    0.068</td> <td>  100.470</td> <td> 0.000</td> <td>    6.697</td> <td>    6.964</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agepreg</th>   <td>    0.0175</td> <td>    0.003</td> <td>    6.559</td> <td> 0.000</td> <td>    0.012</td> <td>    0.023</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1024.052</td> <th>  Durbin-Watson:     </th> <td>   1.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3081.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.601</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 5.596</td>  <th>  Cond. No.          </th> <td>    118.</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            totalwgt_lb   R-squared:                       0.005\n",
       "Model:                            OLS   Adj. R-squared:                  0.005\n",
       "Method:                 Least Squares   F-statistic:                     43.02\n",
       "Date:                Wed, 27 Jun 2018   Prob (F-statistic):           5.72e-11\n",
       "Time:                        15:06:50   Log-Likelihood:                -15897.\n",
       "No. Observations:                9038   AIC:                         3.180e+04\n",
       "Df Residuals:                    9036   BIC:                         3.181e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      6.8304      0.068    100.470      0.000       6.697       6.964\n",
       "agepreg        0.0175      0.003      6.559      0.000       0.012       0.023\n",
       "==============================================================================\n",
       "Omnibus:                     1024.052   Durbin-Watson:                   1.618\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3081.833\n",
       "Skew:                          -0.601   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.596   Cond. No.                         118.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "formula = 'totalwgt_lb ~ agepreg'\n",
    "model = smf.ols(formula, data=live)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.830396973311048, 0.017453851471802843)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter = results.params['Intercept']\n",
    "slope = results.params['agepreg']\n",
    "inter, slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the p-value of the slope estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7229471073134105e-11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope_pvalue = results.pvalues['agepreg']\n",
    "slope_pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the coefficient of determination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004738115474710258"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in birth weight between first babies and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12476118453549034"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_weight = firsts.totalwgt_lb.mean() - others.totalwgt_lb.mean()\n",
    "diff_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in age between mothers of first babies and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.586434766150152"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_age = firsts.agepreg.mean() - others.agepreg.mean()\n",
    "diff_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age difference plausibly explains about half of the difference in weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06259709972169471"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope * diff_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a single regression with a categorical variable, `isfirst`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>totalwgt_lb</td>   <th>  R-squared:         </th> <td>   0.002</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.002</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   17.74</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 27 Jun 2018</td> <th>  Prob (F-statistic):</th> <td>2.55e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:06:50</td>     <th>  Log-Likelihood:    </th> <td> -15909.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  9038</td>      <th>  AIC:               </th> <td>3.182e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9036</td>      <th>  BIC:               </th> <td>3.184e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>    7.3259</td> <td>    0.021</td> <td>  356.007</td> <td> 0.000</td> <td>    7.286</td> <td>    7.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isfirst[T.True]</th> <td>   -0.1248</td> <td>    0.030</td> <td>   -4.212</td> <td> 0.000</td> <td>   -0.183</td> <td>   -0.067</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>988.919</td> <th>  Durbin-Watson:     </th> <td>   1.613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2897.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.589</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.511</td>  <th>  Cond. No.          </th> <td>    2.58</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            totalwgt_lb   R-squared:                       0.002\n",
       "Model:                            OLS   Adj. R-squared:                  0.002\n",
       "Method:                 Least Squares   F-statistic:                     17.74\n",
       "Date:                Wed, 27 Jun 2018   Prob (F-statistic):           2.55e-05\n",
       "Time:                        15:06:50   Log-Likelihood:                -15909.\n",
       "No. Observations:                9038   AIC:                         3.182e+04\n",
       "Df Residuals:                    9036   BIC:                         3.184e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept           7.3259      0.021    356.007      0.000       7.286       7.366\n",
       "isfirst[T.True]    -0.1248      0.030     -4.212      0.000      -0.183      -0.067\n",
       "==============================================================================\n",
       "Omnibus:                      988.919   Durbin-Watson:                   1.613\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2897.107\n",
       "Skew:                          -0.589   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.511   Cond. No.                         2.58\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "live['isfirst'] = live.birthord == 1\n",
    "formula = 'totalwgt_lb ~ isfirst'\n",
    "results = smf.ols(formula, data=live).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finally running a multiple regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>totalwgt_lb</td>   <th>  R-squared:         </th> <td>   0.005</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.005</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 27 Jun 2018</td> <th>  Prob (F-statistic):</th> <td>3.95e-11</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:06:50</td>     <th>  Log-Likelihood:    </th> <td> -15894.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  9038</td>      <th>  AIC:               </th> <td>3.179e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9035</td>      <th>  BIC:               </th> <td>3.182e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>    6.9142</td> <td>    0.078</td> <td>   89.073</td> <td> 0.000</td> <td>    6.762</td> <td>    7.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isfirst[T.True]</th> <td>   -0.0698</td> <td>    0.031</td> <td>   -2.236</td> <td> 0.025</td> <td>   -0.131</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agepreg</th>         <td>    0.0154</td> <td>    0.003</td> <td>    5.499</td> <td> 0.000</td> <td>    0.010</td> <td>    0.021</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1019.945</td> <th>  Durbin-Watson:     </th> <td>   1.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3063.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.599</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 5.588</td>  <th>  Cond. No.          </th> <td>    137.</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            totalwgt_lb   R-squared:                       0.005\n",
       "Model:                            OLS   Adj. R-squared:                  0.005\n",
       "Method:                 Least Squares   F-statistic:                     24.02\n",
       "Date:                Wed, 27 Jun 2018   Prob (F-statistic):           3.95e-11\n",
       "Time:                        15:06:50   Log-Likelihood:                -15894.\n",
       "No. Observations:                9038   AIC:                         3.179e+04\n",
       "Df Residuals:                    9035   BIC:                         3.182e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept           6.9142      0.078     89.073      0.000       6.762       7.066\n",
       "isfirst[T.True]    -0.0698      0.031     -2.236      0.025      -0.131      -0.009\n",
       "agepreg             0.0154      0.003      5.499      0.000       0.010       0.021\n",
       "==============================================================================\n",
       "Omnibus:                     1019.945   Durbin-Watson:                   1.618\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3063.682\n",
       "Skew:                          -0.599   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.588   Cond. No.                         137.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = 'totalwgt_lb ~ isfirst + agepreg'\n",
    "results = smf.ols(formula, data=live).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, when we control for mother's age, the apparent difference due to `isfirst` is cut in half.\n",
    "\n",
    "If we add age squared, we can control for a quadratic relationship between age and weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>totalwgt_lb</td>   <th>  R-squared:         </th> <td>   0.007</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.007</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   22.64</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 27 Jun 2018</td> <th>  Prob (F-statistic):</th> <td>1.35e-14</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:06:50</td>     <th>  Log-Likelihood:    </th> <td> -15884.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  9038</td>      <th>  AIC:               </th> <td>3.178e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9034</td>      <th>  BIC:               </th> <td>3.181e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>    5.6923</td> <td>    0.286</td> <td>   19.937</td> <td> 0.000</td> <td>    5.133</td> <td>    6.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isfirst[T.True]</th> <td>   -0.0504</td> <td>    0.031</td> <td>   -1.602</td> <td> 0.109</td> <td>   -0.112</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agepreg</th>         <td>    0.1124</td> <td>    0.022</td> <td>    5.113</td> <td> 0.000</td> <td>    0.069</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agepreg2</th>        <td>   -0.0018</td> <td>    0.000</td> <td>   -4.447</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1007.149</td> <th>  Durbin-Watson:     </th> <td>   1.616</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3003.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.594</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 5.562</td>  <th>  Cond. No.          </th> <td>1.39e+04</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            totalwgt_lb   R-squared:                       0.007\n",
       "Model:                            OLS   Adj. R-squared:                  0.007\n",
       "Method:                 Least Squares   F-statistic:                     22.64\n",
       "Date:                Wed, 27 Jun 2018   Prob (F-statistic):           1.35e-14\n",
       "Time:                        15:06:50   Log-Likelihood:                -15884.\n",
       "No. Observations:                9038   AIC:                         3.178e+04\n",
       "Df Residuals:                    9034   BIC:                         3.181e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept           5.6923      0.286     19.937      0.000       5.133       6.252\n",
       "isfirst[T.True]    -0.0504      0.031     -1.602      0.109      -0.112       0.011\n",
       "agepreg             0.1124      0.022      5.113      0.000       0.069       0.155\n",
       "agepreg2           -0.0018      0.000     -4.447      0.000      -0.003      -0.001\n",
       "==============================================================================\n",
       "Omnibus:                     1007.149   Durbin-Watson:                   1.616\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3003.343\n",
       "Skew:                          -0.594   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.562   Cond. No.                     1.39e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.39e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "live['agepreg2'] = live.agepreg**2\n",
    "formula = 'totalwgt_lb ~ isfirst + agepreg + agepreg2'\n",
    "results = smf.ols(formula, data=live).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we do that, the apparent effect of `isfirst` gets even smaller, and is no longer statistically significant.\n",
    "\n",
    "These results suggest that the apparent difference in weight between first babies and others might be explained by difference in mothers' ages, at least in part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining\n",
    "\n",
    "We can use `join` to combine variables from the preganancy and respondent tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nsfg\n",
    "\n",
    "live = live[live.prglngth>30]\n",
    "resp = nsfg.ReadFemResp()\n",
    "resp.index = resp.caseid\n",
    "join = live.join(resp, on='caseid', rsuffix='_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can search for variables with explanatory power.\n",
    "\n",
    "Because we don't clean most of the variables, we are probably missing some good ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GoMining(df):\n",
    "    \"\"\"Searches for variables that predict birth weight.\n",
    "\n",
    "    df: DataFrame of pregnancy records\n",
    "\n",
    "    returns: list of (rsquared, variable name) pairs\n",
    "    \"\"\"\n",
    "    variables = []\n",
    "    for name in df.columns:\n",
    "        try:\n",
    "            if df[name].var() < 1e-7:\n",
    "                continue\n",
    "\n",
    "            formula = 'totalwgt_lb ~ agepreg + ' + name\n",
    "            #formula = formula.encode('ascii')\n",
    "\n",
    "            model = smf.ols(formula, data=df)\n",
    "            if model.nobs < len(df)/2:\n",
    "                continue\n",
    "\n",
    "            results = model.fit()\n",
    "        except (ValueError, TypeError):\n",
    "            continue\n",
    "        #except patsy.PatsyError:\n",
    "           # raise ValueError(MESSAGE)\n",
    "\n",
    "        variables.append((results.rsquared, name))\n",
    "\n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = GoMining(join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions report the variables with the highest values of $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def ReadVariables():\n",
    "    \"\"\"Reads Stata dictionary files for NSFG data.\n",
    "\n",
    "    returns: DataFrame that maps variables names to descriptions\n",
    "    \"\"\"\n",
    "    vars1 = thinkstats2.ReadStataDct('2002FemPreg.dct').variables\n",
    "    vars2 = thinkstats2.ReadStataDct('2002FemResp.dct').variables\n",
    "\n",
    "    all_vars = vars1.append(vars2)\n",
    "    all_vars.index = all_vars.name\n",
    "    return all_vars\n",
    "\n",
    "def MiningReport(variables, n=30):\n",
    "    \"\"\"Prints variables with the highest R^2.\n",
    "\n",
    "    t: list of (R^2, variable name) pairs\n",
    "    n: number of pairs to print\n",
    "    \"\"\"\n",
    "    all_vars = ReadVariables()\n",
    "\n",
    "    variables.sort(reverse=True)\n",
    "    for r2, name in variables[:n]:\n",
    "        key = re.sub('_r$', '', name)\n",
    "        try:\n",
    "            desc = all_vars.loc[key].desc\n",
    "            if isinstance(desc, pd.Series):\n",
    "                desc = desc[0]\n",
    "            print(name, r2, desc)\n",
    "        except KeyError:\n",
    "            print(name, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the variables that do well are not useful for prediction because they are not known ahead of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalwgt_lb 1.0\n",
      "birthwgt_lb 0.9498127305978009 BD-3 BIRTHWEIGHT IN POUNDS - 1ST BABY FROM THIS PREGNANCY\n",
      "lbw1 0.3008240784470769 LOW BIRTHWEIGHT - BABY 1\n",
      "prglngth 0.13012519488625063 DURATION OF COMPLETED PREGNANCY IN WEEKS\n",
      "wksgest 0.12340041363361054 GESTATIONAL LENGTH OF COMPLETED PREGNANCY (IN WEEKS)\n",
      "agecon 0.10203149928156052 AGE AT TIME OF CONCEPTION\n",
      "mosgest 0.027144274639579802 GESTATIONAL LENGTH OF COMPLETED PREGNANCY (IN MONTHS)\n",
      "babysex 0.01855092529394209 BD-2 SEX OF 1ST LIVEBORN BABY FROM THIS PREGNANCY\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2559\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 2560\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   2561\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8c7be7484676>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMiningReport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-fcdb9ad3440d>\u001b[0m in \u001b[0;36mMiningReport\u001b[0;34m(variables, n)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2578\u001b[0m             \u001b[0;31m# python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2579\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2580\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2581\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "MiningReport(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the variables that seem to have the most explanatory power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>totalwgt_lb</td>   <th>  R-squared:         </th> <td>   0.060</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.059</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   79.98</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 27 Jun 2018</td> <th>  Prob (F-statistic):</th> <td>4.86e-113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:09:55</td>     <th>  Log-Likelihood:    </th> <td> -14295.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8781</td>      <th>  AIC:               </th> <td>2.861e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8773</td>      <th>  BIC:               </th> <td>2.866e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>    6.6303</td> <td>    0.065</td> <td>  102.223</td> <td> 0.000</td> <td>    6.503</td> <td>    6.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(race)[T.2]</th>         <td>    0.3570</td> <td>    0.032</td> <td>   11.215</td> <td> 0.000</td> <td>    0.295</td> <td>    0.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(race)[T.3]</th>         <td>    0.2665</td> <td>    0.051</td> <td>    5.175</td> <td> 0.000</td> <td>    0.166</td> <td>    0.367</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>babysex == 1[T.True]</th> <td>    0.2952</td> <td>    0.026</td> <td>   11.216</td> <td> 0.000</td> <td>    0.244</td> <td>    0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nbrnaliv > 1[T.True]</th> <td>   -1.3783</td> <td>    0.108</td> <td>  -12.771</td> <td> 0.000</td> <td>   -1.590</td> <td>   -1.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>paydu == 1[T.True]</th>   <td>    0.1196</td> <td>    0.031</td> <td>    3.861</td> <td> 0.000</td> <td>    0.059</td> <td>    0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agepreg</th>              <td>    0.0074</td> <td>    0.003</td> <td>    2.921</td> <td> 0.004</td> <td>    0.002</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>totincr</th>              <td>    0.0122</td> <td>    0.004</td> <td>    3.110</td> <td> 0.002</td> <td>    0.005</td> <td>    0.020</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>398.813</td> <th>  Durbin-Watson:     </th> <td>   1.604</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1388.362</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.037</td>  <th>  Prob(JB):          </th> <td>3.32e-302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.947</td>  <th>  Cond. No.          </th> <td>    221.</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            totalwgt_lb   R-squared:                       0.060\n",
       "Model:                            OLS   Adj. R-squared:                  0.059\n",
       "Method:                 Least Squares   F-statistic:                     79.98\n",
       "Date:                Wed, 27 Jun 2018   Prob (F-statistic):          4.86e-113\n",
       "Time:                        15:09:55   Log-Likelihood:                -14295.\n",
       "No. Observations:                8781   AIC:                         2.861e+04\n",
       "Df Residuals:                    8773   BIC:                         2.866e+04\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "Intercept                6.6303      0.065    102.223      0.000       6.503       6.757\n",
       "C(race)[T.2]             0.3570      0.032     11.215      0.000       0.295       0.419\n",
       "C(race)[T.3]             0.2665      0.051      5.175      0.000       0.166       0.367\n",
       "babysex == 1[T.True]     0.2952      0.026     11.216      0.000       0.244       0.347\n",
       "nbrnaliv > 1[T.True]    -1.3783      0.108    -12.771      0.000      -1.590      -1.167\n",
       "paydu == 1[T.True]       0.1196      0.031      3.861      0.000       0.059       0.180\n",
       "agepreg                  0.0074      0.003      2.921      0.004       0.002       0.012\n",
       "totincr                  0.0122      0.004      3.110      0.002       0.005       0.020\n",
       "==============================================================================\n",
       "Omnibus:                      398.813   Durbin-Watson:                   1.604\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1388.362\n",
       "Skew:                          -0.037   Prob(JB):                    3.32e-302\n",
       "Kurtosis:                       4.947   Cond. No.                         221.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = ('totalwgt_lb ~ agepreg + C(race) + babysex==1 + '\n",
    "               'nbrnaliv>1 + paydu==1 + totincr')\n",
    "results = smf.ols(formula, data=join).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "Example: suppose we are trying to predict `y` using explanatory variables `x1` and `x2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0, 1, 0, 1])\n",
    "x1 = np.array([0, 0, 0, 1])\n",
    "x2 = np.array([0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the logit model the log odds for the $i$th element of $y$ is\n",
    "\n",
    "$\\log o = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 $\n",
    "\n",
    "So let's start with an arbitrary guess about the elements of $\\beta$:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = [-1.5, 2.8, 1.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plugging in the model, we get log odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.5, -0.4, -0.4,  2.4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_o = beta[0] + beta[1] * x1 + beta[2] * x2\n",
    "log_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which we can convert to odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22313016,  0.67032005,  0.67032005, 11.02317638])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = np.exp(log_o)\n",
    "o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then convert to probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18242552, 0.40131234, 0.40131234, 0.9168273 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = o / (o+1)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihoods of the actual outcomes are $p$ where $y$ is 1 and $1-p$ where $y$ is 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81757448, 0.40131234, 0.59868766, 0.9168273 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes = np.where(y, p, 1-p)\n",
    "likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood of $y$ given $\\beta$ is the product of `likes`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1800933529673034"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "like = np.prod(likes)\n",
    "like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression works by searching for the values in $\\beta$ that maximize `like`.\n",
    "\n",
    "Here's an example using variables in the NSFG respondent file to predict whether a baby will be a boy or a girl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import first\n",
    "live, firsts, others = first.MakeFrames()\n",
    "live = live[live.prglngth>30]\n",
    "live['boy'] = (live.babysex==1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mother's age seems to have a small effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.693015\n",
      "         Iterations 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>       <td>No. Iterations:</td>    <td>3.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>        <td>boy</td>       <td>Pseudo R-squared:</td>    <td>0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2018-06-27 15:10</td>       <td>AIC:</td>        <td>12317.4937</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>8884</td>             <td>BIC:</td>        <td>12331.6777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>         <td>Log-Likelihood:</td>    <td>-6156.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>8882</td>           <td>LL-Null:</td>        <td>-6156.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th> <th>Std.Err.</th>    <th>z</th>    <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>0.0058</td>  <td>0.0975</td>  <td>0.0593</td> <td>0.9527</td> <td>-0.1854</td> <td>0.1969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agepreg</th>   <td>0.0010</td>  <td>0.0038</td>  <td>0.2751</td> <td>0.7833</td> <td>-0.0064</td> <td>0.0085</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            No. Iterations:   3.0000    \n",
       "Dependent Variable: boy              Pseudo R-squared: 0.000     \n",
       "Date:               2018-06-27 15:10 AIC:              12317.4937\n",
       "No. Observations:   8884             BIC:              12331.6777\n",
       "Df Model:           1                Log-Likelihood:   -6156.7   \n",
       "Df Residuals:       8882             LL-Null:          -6156.8   \n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "-------------------------------------------------------------------\n",
       "             Coef.    Std.Err.     z      P>|z|     [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "Intercept    0.0058     0.0975   0.0593   0.9527   -0.1854   0.1969\n",
       "agepreg      0.0010     0.0038   0.2751   0.7833   -0.0064   0.0085\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smf.logit('boy ~ agepreg', data=live)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the variables that seemed most promising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692944\n",
      "         Iterations 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>       <td>No. Iterations:</td>    <td>3.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>        <td>boy</td>       <td>Pseudo R-squared:</td>    <td>0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2018-06-27 15:10</td>       <td>AIC:</td>        <td>12182.8769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>8782</td>             <td>BIC:</td>        <td>12225.3597</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>5</td>         <td>Log-Likelihood:</td>    <td>-6085.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>8776</td>           <td>LL-Null:</td>        <td>-6086.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>        <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>-0.0301</td>  <td>0.1039</td>  <td>-0.2902</td> <td>0.7717</td> <td>-0.2337</td> <td>0.1734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(race)[T.2]</th> <td>-0.0224</td>  <td>0.0509</td>  <td>-0.4393</td> <td>0.6604</td> <td>-0.1222</td> <td>0.0775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(race)[T.3]</th> <td>-0.0005</td>  <td>0.0831</td>  <td>-0.0055</td> <td>0.9956</td> <td>-0.1634</td> <td>0.1625</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agepreg</th>      <td>-0.0027</td>  <td>0.0055</td>  <td>-0.4836</td> <td>0.6286</td> <td>-0.0135</td> <td>0.0082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hpagelb</th>      <td>0.0047</td>   <td>0.0042</td>  <td>1.1118</td>  <td>0.2662</td> <td>-0.0036</td> <td>0.0130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>birthord</th>     <td>0.0050</td>   <td>0.0221</td>  <td>0.2268</td>  <td>0.8206</td> <td>-0.0383</td> <td>0.0483</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            No. Iterations:   3.0000    \n",
       "Dependent Variable: boy              Pseudo R-squared: 0.000     \n",
       "Date:               2018-06-27 15:10 AIC:              12182.8769\n",
       "No. Observations:   8782             BIC:              12225.3597\n",
       "Df Model:           5                Log-Likelihood:   -6085.4   \n",
       "Df Residuals:       8776             LL-Null:          -6086.3   \n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "------------------------------------------------------------------\n",
       "                Coef.   Std.Err.     z     P>|z|    [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "Intercept      -0.0301    0.1039  -0.2902  0.7717  -0.2337  0.1734\n",
       "C(race)[T.2]   -0.0224    0.0509  -0.4393  0.6604  -0.1222  0.0775\n",
       "C(race)[T.3]   -0.0005    0.0831  -0.0055  0.9956  -0.1634  0.1625\n",
       "agepreg        -0.0027    0.0055  -0.4836  0.6286  -0.0135  0.0082\n",
       "hpagelb         0.0047    0.0042   1.1118  0.2662  -0.0036  0.0130\n",
       "birthord        0.0050    0.0221   0.2268  0.8206  -0.0383  0.0483\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = 'boy ~ agepreg + hpagelb + birthord + C(race)'\n",
    "model = smf.logit(formula, data=live)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a prediction, we have to extract the exogenous and endogenous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "endog = pd.DataFrame(model.endog, columns=[model.endog_names])\n",
    "exog = pd.DataFrame(model.exog, columns=model.exog_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline prediction strategy is to guess \"boy\".  In that case, we're right almost 51% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.507173764518333"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = endog['boy']\n",
    "baseline = actual.mean()\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the previous model, we can compute the number of predictions we get right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3944.0, 548.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = (results.predict() >= 0.5)\n",
    "true_pos = predict * actual\n",
    "true_neg = (1 - predict) * (1 - actual)\n",
    "sum(true_pos), sum(true_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the accuracy, which is slightly higher than the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5115007970849464"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = (sum(true_pos) + sum(true_neg)) / len(actual)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a prediction for an individual, we have to get their information into a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.513091\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['agepreg', 'hpagelb', 'birthord', 'race']\n",
    "new = pd.DataFrame([[35, 39, 3, 2]], columns=columns)\n",
    "y = results.predict(new)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This person has a 51% chance of having a boy (according to the model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Exercise:** Suppose one of your co-workers is expecting a baby and you are participating in an office pool to predict the date of birth. Assuming that bets are placed during the 30th week of pregnancy, what variables could you use to make the best prediction? You should limit yourself to variables that are known before the birth, and likely to be available to the people in the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import first\n",
    "live, firsts, others = first.MakeFrames()\n",
    "live = live[live.prglngth>30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the only variables I found that have a statistically significant effect on pregnancy length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>prglngth</td>     <th>  R-squared:         </th> <td>   0.011</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.011</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.28</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 27 Jun 2018</td> <th>  Prob (F-statistic):</th> <td>5.09e-22</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:10:32</td>     <th>  Log-Likelihood:    </th> <td> -18247.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8884</td>      <th>  AIC:               </th> <td>3.650e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8880</td>      <th>  BIC:               </th> <td>3.653e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>             <td>   38.7617</td> <td>    0.039</td> <td> 1006.410</td> <td> 0.000</td> <td>   38.686</td> <td>   38.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>birthord == 1[T.True]</th> <td>    0.1015</td> <td>    0.040</td> <td>    2.528</td> <td> 0.011</td> <td>    0.023</td> <td>    0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race == 2[T.True]</th>     <td>    0.1390</td> <td>    0.042</td> <td>    3.311</td> <td> 0.001</td> <td>    0.057</td> <td>    0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nbrnaliv > 1[T.True]</th>  <td>   -1.4944</td> <td>    0.164</td> <td>   -9.086</td> <td> 0.000</td> <td>   -1.817</td> <td>   -1.172</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1587.470</td> <th>  Durbin-Watson:     </th> <td>   1.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6160.751</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.852</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 6.707</td>  <th>  Cond. No.          </th> <td>    10.9</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               prglngth   R-squared:                       0.011\n",
       "Model:                            OLS   Adj. R-squared:                  0.011\n",
       "Method:                 Least Squares   F-statistic:                     34.28\n",
       "Date:                Wed, 27 Jun 2018   Prob (F-statistic):           5.09e-22\n",
       "Time:                        15:10:32   Log-Likelihood:                -18247.\n",
       "No. Observations:                8884   AIC:                         3.650e+04\n",
       "Df Residuals:                    8880   BIC:                         3.653e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================\n",
       "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "Intercept                38.7617      0.039   1006.410      0.000      38.686      38.837\n",
       "birthord == 1[T.True]     0.1015      0.040      2.528      0.011       0.023       0.180\n",
       "race == 2[T.True]         0.1390      0.042      3.311      0.001       0.057       0.221\n",
       "nbrnaliv > 1[T.True]     -1.4944      0.164     -9.086      0.000      -1.817      -1.172\n",
       "==============================================================================\n",
       "Omnibus:                     1587.470   Durbin-Watson:                   1.619\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6160.751\n",
       "Skew:                          -0.852   Prob(JB):                         0.00\n",
       "Kurtosis:                       6.707   Cond. No.                         10.9\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "model = smf.ols('prglngth ~ birthord==1 + race==2 + nbrnaliv>1', data=live)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** The Trivers-Willard hypothesis suggests that for many mammals the sex ratio depends on “maternal condition”; that is, factors like the mother’s age, size, health, and social status. See https://en.wikipedia.org/wiki/Trivers-Willard_hypothesis\n",
    "\n",
    "Some studies have shown this effect among humans, but results are mixed. In this chapter we tested some variables related to these factors, but didn’t find any with a statistically significant effect on sex ratio.\n",
    "\n",
    "As an exercise, use a data mining approach to test the other variables in the pregnancy and respondent files. Can you find any factors with a substantial effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regression\n",
    "join = regression.JoinFemResp(live)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = GoMining(join)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 'totalwgt_lb'),\n",
       " (0.9498127305978009, 'birthwgt_lb'),\n",
       " (0.3008240784470769, 'lbw1'),\n",
       " (0.13012519488625063, 'prglngth'),\n",
       " (0.12340041363361054, 'wksgest'),\n",
       " (0.10203149928156052, 'agecon'),\n",
       " (0.027144274639579802, 'mosgest'),\n",
       " (0.01855092529394209, 'babysex'),\n",
       " (0.016199503586253217, 'race_r'),\n",
       " (0.016199503586253217, 'race'),\n",
       " (0.016017752709788113, 'nbrnaliv'),\n",
       " (0.014003795578114597, 'paydu'),\n",
       " (0.013430066465713209, 'rmarout03'),\n",
       " (0.013102457615706053, 'birthwgt_oz'),\n",
       " (0.012529022541810764, 'anynurse'),\n",
       " (0.01219368840449575, 'bfeedwks'),\n",
       " (0.011870069031173491, 'totincr'),\n",
       " (0.011807801994375033, 'marout03'),\n",
       " (0.011752599354395654, 'marcon03'),\n",
       " (0.011437770919637158, 'cebow')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables.sort(reverse=True)\n",
    "variables[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692874\n",
      "         Iterations 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>       <td>No. Iterations:</td>    <td>3.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>        <td>boy</td>       <td>Pseudo R-squared:</td>    <td>0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2018-06-27 15:20</td>       <td>AIC:</td>        <td>12322.9842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>8884</td>             <td>BIC:</td>        <td>12365.5362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>5</td>         <td>Log-Likelihood:</td>    <td>-6155.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>8878</td>           <td>LL-Null:</td>        <td>-6156.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>           <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>0.0487</td>   <td>0.0997</td>  <td>0.4879</td>  <td>0.6256</td> <td>-0.1468</td> <td>0.2441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(race)[T.2]</th>       <td>-0.0306</td>  <td>0.0513</td>  <td>-0.5966</td> <td>0.5508</td> <td>-0.1311</td> <td>0.0699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(race)[T.3]</th>       <td>-0.0005</td>  <td>0.0824</td>  <td>-0.0057</td> <td>0.9955</td> <td>-0.1620</td> <td>0.1611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>paydu == 1[T.True]</th> <td>0.0375</td>   <td>0.0500</td>  <td>0.7497</td>  <td>0.4534</td> <td>-0.0605</td> <td>0.1355</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agecon</th>             <td>0.0000</td>   <td>0.0000</td>  <td>0.5820</td>  <td>0.5606</td> <td>-0.0001</td> <td>0.0001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>totincr</th>            <td>-0.0087</td>  <td>0.0063</td>  <td>-1.3736</td> <td>0.1696</td> <td>-0.0211</td> <td>0.0037</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            No. Iterations:   3.0000    \n",
       "Dependent Variable: boy              Pseudo R-squared: 0.000     \n",
       "Date:               2018-06-27 15:20 AIC:              12322.9842\n",
       "No. Observations:   8884             BIC:              12365.5362\n",
       "Df Model:           5                Log-Likelihood:   -6155.5   \n",
       "Df Residuals:       8878             LL-Null:          -6156.8   \n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "-----------------------------------------------------------------\n",
       "                    Coef.  Std.Err.    z    P>|z|   [0.025 0.975]\n",
       "-----------------------------------------------------------------\n",
       "Intercept           0.0487   0.0997  0.4879 0.6256 -0.1468 0.2441\n",
       "C(race)[T.2]       -0.0306   0.0513 -0.5966 0.5508 -0.1311 0.0699\n",
       "C(race)[T.3]       -0.0005   0.0824 -0.0057 0.9955 -0.1620 0.1611\n",
       "paydu == 1[T.True]  0.0375   0.0500  0.7497 0.4534 -0.0605 0.1355\n",
       "agecon              0.0000   0.0000  0.5820 0.5606 -0.0001 0.0001\n",
       "totincr            -0.0087   0.0063 -1.3736 0.1696 -0.0211 0.0037\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join['boy'] = (join.babysex==1).astype(int)\n",
    "formula = ('boy ~ agecon + C(race) + paydu==1 +totincr')\n",
    "results = smf.logit(formula, data=join).fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** If the quantity you want to predict is a count, you can use Poisson regression, which is implemented in StatsModels with a function called `poisson`. It works the same way as `ols` and `logit`. As an exercise, let’s use it to predict how many children a woman has born; in the NSFG dataset, this variable is called `numbabes`.\n",
    "\n",
    "Suppose you meet a woman who is 35 years old, black, and a college graduate whose annual household income exceeds $75,000. How many children would you predict she has born?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here\n",
    "import nsfg\n",
    "\n",
    "live = live[live.prglngth>30]\n",
    "resp = nsfg.ReadFemResp()\n",
    "resp.index = resp.caseid\n",
    "join = live.join(resp, on='caseid', rsuffix='_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.696421\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>             <td>Poisson</td>      <td>No. Iterations:</td>    <td>7.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>numbabes</td>     <td>Pseudo R-squared:</td>    <td>0.026</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2018-06-27 15:25</td>       <td>AIC:</td>        <td>30154.0037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>8884</td>             <td>BIC:</td>        <td>30196.5558</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>5</td>         <td>Log-Likelihood:</td>    <td>-15071.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>8878</td>           <td>LL-Null:</td>        <td>-15469.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>            <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>0.6342</td>   <td>0.0363</td>   <td>17.4628</td> <td>0.0000</td> <td>0.5630</td>  <td>0.7054</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(race)[T.2]</th>         <td>-0.1315</td>  <td>0.0148</td>   <td>-8.8939</td> <td>0.0000</td> <td>-0.1605</td> <td>-0.1025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(race)[T.3]</th>         <td>-0.0780</td>  <td>0.0246</td>   <td>-3.1735</td> <td>0.0015</td> <td>-0.1262</td> <td>-0.0298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>havedeg == 1[T.True]</th> <td>-0.1377</td>  <td>0.0172</td>   <td>-8.0043</td> <td>0.0000</td> <td>-0.1715</td> <td>-0.1040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>totincr</th>              <td>-0.0252</td>  <td>0.0018</td>  <td>-13.8415</td> <td>0.0000</td> <td>-0.0288</td> <td>-0.0217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ager</th>                 <td>0.0203</td>   <td>0.0010</td>   <td>19.9855</td> <td>0.0000</td> <td>0.0183</td>  <td>0.0223</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Poisson\n",
       "=====================================================================\n",
       "Model:                Poisson           No. Iterations:    7.0000    \n",
       "Dependent Variable:   numbabes          Pseudo R-squared:  0.026     \n",
       "Date:                 2018-06-27 15:25  AIC:               30154.0037\n",
       "No. Observations:     8884              BIC:               30196.5558\n",
       "Df Model:             5                 Log-Likelihood:    -15071.   \n",
       "Df Residuals:         8878              LL-Null:           -15469.   \n",
       "Converged:            1.0000            Scale:             1.0000    \n",
       "---------------------------------------------------------------------\n",
       "                      Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
       "---------------------------------------------------------------------\n",
       "Intercept             0.6342   0.0363  17.4628 0.0000  0.5630  0.7054\n",
       "C(race)[T.2]         -0.1315   0.0148  -8.8939 0.0000 -0.1605 -0.1025\n",
       "C(race)[T.3]         -0.0780   0.0246  -3.1735 0.0015 -0.1262 -0.0298\n",
       "havedeg == 1[T.True] -0.1377   0.0172  -8.0043 0.0000 -0.1715 -0.1040\n",
       "totincr              -0.0252   0.0018 -13.8415 0.0000 -0.0288 -0.0217\n",
       "ager                  0.0203   0.0010  19.9855 0.0000  0.0183  0.0223\n",
       "=====================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution goes here\n",
    "formula = ('numbabes ~ C(race) + totincr + ager + havedeg==1')\n",
    "results = smf.poisson(formula, data=join).fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict the number of children for a woman who is 35 years old, black, and a college\n",
    "graduate whose annual household income exceeds $75,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.350512\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution goes here\n",
    "columns = ['race', 'totincr', 'ager', 'havedeg']\n",
    "new = pd.DataFrame([[1, 14, 35, 1]], columns=columns)\n",
    "x = results.predict(new)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** If the quantity you want to predict is categorical, you can use multinomial logistic regression, which is implemented in StatsModels with a function called `mnlogit`. As an exercise, let’s use it to guess whether a woman is married, cohabitating, widowed, divorced, separated, or never married; in the NSFG dataset, marital status is encoded in a variable called `rmarital`.\n",
    "\n",
    "Suppose you meet a woman who is 25 years old, white, and a high school graduate whose annual household income is about $45,000. What is the probability that she is married, cohabitating, etc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.089033\n",
      "         Iterations 8\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (6,) (6,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-d32f844256b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mformula\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rmarital ~ ager + C(race) + totincr + hieduc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnlogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36msummary2\u001b[0;34m(self, alpha, float_format)\u001b[0m\n\u001b[1;32m   3041\u001b[0m             coefs = summary2.summary_params(self, alpha, self.params[:,i],\n\u001b[1;32m   3042\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3043\u001b[0;31m                     confint[i])\n\u001b[0m\u001b[1;32m   3044\u001b[0m             \u001b[0;31m# Header must show value of endog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3045\u001b[0m             \u001b[0mlevel_str\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/statsmodels/iolib/summary2.py\u001b[0m in \u001b[0;36msummary_params\u001b[0;34m(results, yname, xname, alpha, use_t, skip_header, float_format)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mtvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mpvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mconf_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36mconf_int\u001b[0;34m(self, alpha, cols)\u001b[0m\n\u001b[1;32m   2981\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconf_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m         confint = super(DiscreteResults, self).conf_int(alpha=alpha,\n\u001b[0;32m-> 2983\u001b[0;31m                                                             cols=cols)\n\u001b[0m\u001b[1;32m   2984\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconfint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mconf_int\u001b[0;34m(self, alpha, cols, method)\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m             \u001b[0mlower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m             \u001b[0mupper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6,) (6,5) "
     ]
    }
   ],
   "source": [
    "# Solution goes here\n",
    "formula = 'rmarital ~ ager + C(race) + totincr + hieduc'\n",
    "results = smf.mnlogit(formula, data=join).fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction for a woman who is 25 years old, white, and a high\n",
    "school graduate whose annual household income is about $45,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PandasData' object has no attribute 'design_info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-0902b9c0071a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ager'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'race'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'totincr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hieduc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, exog, transform, *args, **kwargs)\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexog_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# user passed in a dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0mexog_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m             exog = dmatrix(self.model.data.design_info.builder,\n\u001b[0m\u001b[1;32m    776\u001b[0m                            exog, return_type=\"dataframe\")\n\u001b[1;32m    777\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PandasData' object has no attribute 'design_info'"
     ]
    }
   ],
   "source": [
    "# Solution goes here\n",
    "columns = ['ager', 'race', 'totincr', 'hieduc']\n",
    "new = pd.DataFrame([[25, 2, 12, 9]], columns=columns)\n",
    "x = results.predict(new)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
